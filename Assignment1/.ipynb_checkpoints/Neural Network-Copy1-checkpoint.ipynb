{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891, 14)\n"
     ]
    }
   ],
   "source": [
    "# data = pd.read_csv(\"data/titanic_train.csv\")\n",
    "# print(data.shape)\n",
    "# X = data.iloc[:,:11]\n",
    "# y = data.iloc[:,11]\n",
    "# train_X,test_X,train_y,test_y = train_test_split(X, y, random_state=0, test_size=0.15)\n",
    "# train_X,val_X,train_y,val_y = train_test_split(train_X, train_y, random_state=0, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19999, 17)\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"data/letter-recognition.csv\")\n",
    "print(data.shape)\n",
    "X = data.iloc[:,1:]\n",
    "y = data.iloc[:,0]\n",
    "y = pd.get_dummies(y)\n",
    "train_X,test_X,train_y,test_y = train_test_split(X, y, random_state=0, test_size=0.15)\n",
    "train_X,val_X,train_y,val_y = train_test_split(train_X, train_y, random_state=0, test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train x shape:  (13599, 16)\n"
     ]
    }
   ],
   "source": [
    "print(\"train x shape: \",train_X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-13e0b17d49a9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m                 \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_X\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m                 \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mval_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mval_y\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbest_accuracy\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m                     \u001b[0mbest_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0macti\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mreg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m                     \u001b[0mbest_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__nonzero__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    953\u001b[0m         raise ValueError(\"The truth value of a {0} is ambiguous. \"\n\u001b[1;32m    954\u001b[0m                          \u001b[0;34m\"Use a.empty, a.bool(), a.item(), a.any() or a.all().\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 955\u001b[0;31m                          .format(self.__class__.__name__))\n\u001b[0m\u001b[1;32m    956\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    957\u001b[0m     \u001b[0m__bool__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m__nonzero__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all()."
     ]
    }
   ],
   "source": [
    "training_info = list()\n",
    "acti_list = ['identity','logistic', 'tanh', 'relu']\n",
    "s_list = ['lbfgs', 'sgd', 'adam']\n",
    "reg_list = [1e-4,1e-3,1e-2]\n",
    "lr_list = ['constant', 'invscaling', 'adaptive']\n",
    "best_accuracy = 0\n",
    "best_info = (None,None,None,None,None)\n",
    "for acti in acti_list:\n",
    "    for s in s_list:\n",
    "        for reg in reg_list:\n",
    "            for lr in lr_list: \n",
    "                nn = MLPClassifier(activation=acti, solver=s, learning_rate=lr, hidden_layer_sizes=(5), random_state=0,alpha=reg)\n",
    "                nn.fit(train_X,train_y)\n",
    "                predictions = nn.predict(val_X)\n",
    "                accuracy = np.sum(predictions == val_y)/val_y.shape[0]\n",
    "                if accuracy > best_accuracy:\n",
    "                    best_info = (acti,s,lr,reg,accuracy)\n",
    "                    best_accuracy = accuracy\n",
    "                print(acti,s,lr,reg,accuracy)\n",
    "                training_info.append((acti,s,lr,reg,accuracy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('tanh', 'lbfgs', 'constant', 0.001, 0.77631578947368418)\n"
     ]
    }
   ],
   "source": [
    "print(best_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "identity lbfgs constant 0.0001 0.671052631579\n",
      "identity lbfgs invscaling 0.0001 0.671052631579\n",
      "identity lbfgs adaptive 0.0001 0.671052631579\n",
      "identity lbfgs constant 0.001 0.697368421053\n",
      "identity lbfgs invscaling 0.001 0.697368421053\n",
      "identity lbfgs adaptive 0.001 0.697368421053\n",
      "identity lbfgs constant 0.01 0.651315789474\n",
      "identity lbfgs invscaling 0.01 0.651315789474\n",
      "identity lbfgs adaptive 0.01 0.651315789474\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jimmy/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "identity sgd constant 0.0001 0.592105263158\n",
      "identity sgd invscaling 0.0001 0.565789473684\n",
      "identity sgd adaptive 0.0001 0.592105263158\n",
      "identity sgd constant 0.001 0.177631578947\n",
      "identity sgd invscaling 0.001 0.565789473684\n",
      "identity sgd adaptive 0.001 0.592105263158\n",
      "identity sgd constant 0.01 0.177631578947\n",
      "identity sgd invscaling 0.01 0.565789473684\n",
      "identity sgd adaptive 0.01 0.592105263158\n",
      "identity adam constant 0.0001 0.578947368421\n",
      "identity adam invscaling 0.0001 0.578947368421\n",
      "identity adam adaptive 0.0001 0.578947368421\n",
      "identity adam constant 0.001 0.578947368421\n",
      "identity adam invscaling 0.001 0.578947368421\n",
      "identity adam adaptive 0.001 0.578947368421\n",
      "identity adam constant 0.01 0.578947368421\n",
      "identity adam invscaling 0.01 0.578947368421\n",
      "identity adam adaptive 0.01 0.578947368421\n",
      "logistic lbfgs constant 0.0001 0.736842105263\n",
      "logistic lbfgs invscaling 0.0001 0.736842105263\n",
      "logistic lbfgs adaptive 0.0001 0.736842105263\n",
      "logistic lbfgs constant 0.001 0.697368421053\n",
      "logistic lbfgs invscaling 0.001 0.697368421053\n",
      "logistic lbfgs adaptive 0.001 0.697368421053\n",
      "logistic lbfgs constant 0.01 0.769736842105\n",
      "logistic lbfgs invscaling 0.01 0.769736842105\n",
      "logistic lbfgs adaptive 0.01 0.769736842105\n",
      "logistic sgd constant 0.0001 0.592105263158\n",
      "logistic sgd invscaling 0.0001 0.0\n",
      "logistic sgd adaptive 0.0001 0.592105263158\n",
      "logistic sgd constant 0.001 0.592105263158\n",
      "logistic sgd invscaling 0.001 0.0\n",
      "logistic sgd adaptive 0.001 0.592105263158\n",
      "logistic sgd constant 0.01 0.592105263158\n",
      "logistic sgd invscaling 0.01 0.0\n",
      "logistic sgd adaptive 0.01 0.592105263158\n",
      "logistic adam constant 0.0001 0.592105263158\n",
      "logistic adam invscaling 0.0001 0.592105263158\n",
      "logistic adam adaptive 0.0001 0.592105263158\n",
      "logistic adam constant 0.001 0.592105263158\n",
      "logistic adam invscaling 0.001 0.592105263158\n",
      "logistic adam adaptive 0.001 0.592105263158\n",
      "logistic adam constant 0.01 0.592105263158\n",
      "logistic adam invscaling 0.01 0.592105263158\n",
      "logistic adam adaptive 0.01 0.592105263158\n",
      "tanh lbfgs constant 0.0001 0.736842105263\n",
      "tanh lbfgs invscaling 0.0001 0.736842105263\n",
      "tanh lbfgs adaptive 0.0001 0.736842105263\n",
      "tanh lbfgs constant 0.001 0.855263157895\n",
      "tanh lbfgs invscaling 0.001 0.855263157895\n",
      "tanh lbfgs adaptive 0.001 0.855263157895\n",
      "tanh lbfgs constant 0.01 0.802631578947\n",
      "tanh lbfgs invscaling 0.01 0.802631578947\n",
      "tanh lbfgs adaptive 0.01 0.802631578947\n",
      "tanh sgd constant 0.0001 0.592105263158\n",
      "tanh sgd invscaling 0.0001 0.00657894736842\n",
      "tanh sgd adaptive 0.0001 0.592105263158\n",
      "tanh sgd constant 0.001 0.592105263158\n",
      "tanh sgd invscaling 0.001 0.00657894736842\n",
      "tanh sgd adaptive 0.001 0.592105263158\n",
      "tanh sgd constant 0.01 0.592105263158\n",
      "tanh sgd invscaling 0.01 0.00657894736842\n",
      "tanh sgd adaptive 0.01 0.592105263158\n",
      "tanh adam constant 0.0001 0.598684210526\n",
      "tanh adam invscaling 0.0001 0.598684210526\n",
      "tanh adam adaptive 0.0001 0.598684210526\n",
      "tanh adam constant 0.001 0.598684210526\n",
      "tanh adam invscaling 0.001 0.598684210526\n",
      "tanh adam adaptive 0.001 0.598684210526\n",
      "tanh adam constant 0.01 0.598684210526\n",
      "tanh adam invscaling 0.01 0.598684210526\n",
      "tanh adam adaptive 0.01 0.598684210526\n",
      "relu lbfgs constant 0.0001 0.592105263158\n",
      "relu lbfgs invscaling 0.0001 0.592105263158\n",
      "relu lbfgs adaptive 0.0001 0.592105263158\n",
      "relu lbfgs constant 0.001 0.592105263158\n",
      "relu lbfgs invscaling 0.001 0.592105263158\n",
      "relu lbfgs adaptive 0.001 0.592105263158\n",
      "relu lbfgs constant 0.01 0.592105263158\n",
      "relu lbfgs invscaling 0.01 0.592105263158\n",
      "relu lbfgs adaptive 0.01 0.592105263158\n",
      "relu sgd constant 0.0001 0.00657894736842\n",
      "relu sgd invscaling 0.0001 0.00657894736842\n",
      "relu sgd adaptive 0.0001 0.00657894736842\n",
      "relu sgd constant 0.001 0.00657894736842\n",
      "relu sgd invscaling 0.001 0.00657894736842\n",
      "relu sgd adaptive 0.001 0.00657894736842\n",
      "relu sgd constant 0.01 0.00657894736842\n",
      "relu sgd invscaling 0.01 0.00657894736842\n",
      "relu sgd adaptive 0.01 0.00657894736842\n",
      "relu adam constant 0.0001 0.578947368421\n",
      "relu adam invscaling 0.0001 0.578947368421\n",
      "relu adam adaptive 0.0001 0.578947368421\n",
      "relu adam constant 0.001 0.578947368421\n",
      "relu adam invscaling 0.001 0.578947368421\n",
      "relu adam adaptive 0.001 0.578947368421\n",
      "relu adam constant 0.01 0.578947368421\n",
      "relu adam invscaling 0.01 0.578947368421\n",
      "relu adam adaptive 0.01 0.578947368421\n"
     ]
    }
   ],
   "source": [
    "training_info = list()\n",
    "acti_list = ['identity','logistic', 'tanh', 'relu']\n",
    "s_list = ['lbfgs', 'sgd', 'adam']\n",
    "reg_list = [1e-4,1e-3,1e-2]\n",
    "lr_list = ['constant', 'invscaling', 'adaptive']\n",
    "best_accuracy = 0\n",
    "best_info = (None,None,None,None,None)\n",
    "for acti in acti_list:\n",
    "    for s in s_list:\n",
    "        for reg in reg_list:\n",
    "            for lr in lr_list: \n",
    "                nn = MLPClassifier(activation=acti, solver=s, learning_rate=lr, hidden_layer_sizes=(8,5), random_state=0,alpha=reg)\n",
    "                nn.fit(train_X,train_y)\n",
    "                predictions = nn.predict(val_X)\n",
    "                accuracy = np.sum(predictions == val_y)/val_y.shape[0]\n",
    "                if accuracy > best_accuracy:\n",
    "                    best_info = (acti,s,lr,reg,accuracy)\n",
    "                    best_accuracy = accuracy\n",
    "                print(acti,s,lr,reg,accuracy)\n",
    "                training_info.append((acti,s,lr,reg,accuracy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('tanh', 'lbfgs', 'constant', 0.001, 0.85526315789473684)\n"
     ]
    }
   ],
   "source": [
    "print(best_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.746268656716\n"
     ]
    }
   ],
   "source": [
    "nn = MLPClassifier(activation='tanh', solver='lbfgs', learning_rate='constant', hidden_layer_sizes=(5), random_state=0,alpha=0.001)\n",
    "nn.fit(train_X,train_y)\n",
    "print(np.sum(nn.predict(test_X)==test_y)/test_y.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.865671641791\n"
     ]
    }
   ],
   "source": [
    "nn = MLPClassifier(activation='tanh', solver='lbfgs', learning_rate='constant', hidden_layer_sizes=(8,5), random_state=0,alpha=0.001)\n",
    "nn.fit(train_X,train_y)\n",
    "print(np.sum(nn.predict(test_X)==test_y)/test_y.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
